{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week - 7 - Deep Neural Nets and Text\n",
    "\n",
    "In this week we introduce the use of Deep Neural Networks to work with text. We have already seen some uses of neural networks for text in our classification HW, where we used a simple neural network--the one-layer perceptron--to classify text. It performed quite well, but comes up short in more sophisticated classification tasks, such as in predicting intent. We have also seen slightly deeper, 2-level neural nets in the form of word embeddings such as Word2Vec. While they work well, they have some drawbacks, such as representing words with multiple meanings in a singular space. \n",
    "\n",
    "BERT, which is a language model built using bidirectional encoders, allows us to take advantage of a powerful pre-trained model which we can then use to perform our own tasks based on data we analyze. \n",
    "\n",
    "In this notebook we use ```huggingface/transformers```, a python package that allows for easy interface to use pre-trained BERT models. It is built using Tensorflow and PyTorch, two computational graph packages which are built specifically for creating powerful neural networks. We will also be introducing Keras, which allows us to easily build Neural Networks in an abstracted way. Keras is a popular way to understand how we can stack layers to create such Neural Networks, but to reach state-of-the-art results we will stick with using BERT and similar models that can be tuned to extremely high performance on specific language understanding and generation tasks.\n",
    "\n",
    "To demonstrate this, we begin by using the [Corpus of Linguistic Acceptability](https://nyu-mll.github.io/CoLA/). We will also use BERT by learning how to extract embeddings from such a model and use it to semantically probe sentences. There are a number of new packages and methods we will be using so be sure to update lucem_illud_2020.\n",
    "\n",
    "## NOTE\n",
    "\n",
    "This notebook **requires** GPUs for training models in section 1 and section 3. To train models, please use this [Google Colab file](https://colab.research.google.com/drive/1_G6iGqiXb-zPBTurRxd7cgGrXyNaKGsA) to create the models. Note that I have only given you view access: please create your own colab file to train your models, using the code and instructions I have given in the Colab file. So while you have to do the homework on this notebook, the models which you will train should be done on Google Colab, which has GPU access. If you happen to have GPU access on your personal machines or some other way to train the models, you are welcome to do that too.\n",
    "\n",
    "Note that if you run the computationally intensive models on your local computer they will take a long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pip install torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig # pip install tranformers==2.4.1\n",
    "from transformers import AdamW, BertForSequenceClassification, BertModel\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lucem_illud_2020 # pip install -U git+git://github.com/Computational-Content-Analysis-2020/lucem_illud_2020.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoLA Dataset and pre-processing\n",
    "\n",
    "We start with loading our dataset and pre-processing it. The pre-processing follows similar steps as we have done in the past, but we will be using pre-written modules offered by the transformers package. These are some of the things we have to take care of when using this particular BERT model.\n",
    "\n",
    "    -special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])\n",
    "    -tokens that conforms with the fixed vocabulary used in BERT\n",
    "    -token IDs from BERTâ€™s tokenizer\n",
    "    -mask IDs to indicate which elements in the sequence are tokens and which are padding elements\n",
    "    -segment IDs used to distinguish different sentences\n",
    "    -positional embeddings used to show token position within the sequence\n",
    "\n",
    "\n",
    "We will be using parts of the code from [this notebook](https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=BJR6t_gCQe_x) which walks us through the process of using a pre-trained BERT model. The interface to use these models comes from the package [huggingface/transformers](https://github.com/huggingface/transformers). \n",
    "\n",
    "We start by setting up our GPU if we can - this may not work on your machine, so it has been commented out.\n",
    "\n",
    "An aside: check out this tutorial too - https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           sentence  label\n",
      "0        1144  September 14  2005 Statement of Senator Hillar...      0\n",
      "1        1968  DARK SIDE OF CHOCOLATE\\n  A delegation of Amer...      0\n",
      "2        1933  SENATE BACKS DRUG IMPORTATION\\n  The Senate vo...      0\n",
      "3        1476  March 18  2005 Senator Clinton Announces Natio...      0\n",
      "4        1358  December 17  2007 Clinton Secures GAO Study on...      0\n",
      "(1005, 3)\n",
      "0    637\n",
      "1    368\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../../data/cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# df.head()\n",
    "df = pd.read_csv('./senate/senate_train.csv')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'september', '14', '2005', 'statement', 'of', 'senator', 'hillary', 'rod', '##ham', 'clinton', 'on', 'senate', 'consideration', 'of', 'the', 'katrina', 'commission', 'washington', 'dc', 'four', 'years', 'ago', 'this', 'week', 'our', 'nation', 'was', 'gr', '##app', '##ling', 'with', 'the', 'catastrophic', 'aftermath', 'of', 'the', 'attacks', 'on', '9', '11', 'what', 'happened', 'on', 'that', 'tragic', 'day', 'changed', 'my', 'state', 'of', 'new', 'york', 'our', 'nation', 's', 'capital', 'and', 'our', 'country', 'forever', 'over', 'the', 'past', 'two', 'weeks', 'we', 'have', 'come', 'to', 'a', 'similar', 'realization', 'about', 'hurricane', 'katrina', 'the', 'hurricane', 'left', 'in', 'its', 'path', 'not', 'just', 'death', 'and', 'devastation', 'but', 'a', 'deep', 'lasting', 'scar', 'and', 'while', 'we', 'must', 'now', 'work', 'to', 'do', 'everything', 'we', 'can', 'to', 'help', 'the', 'victims', 'of', 'this', 'national', 'tragedy', 'we', 'must', 'also', 'do', 'everything', 'we', 'can', 'to', 'make', 'sure', 'that', 'the', 'mistakes', 'that', 'were', 'made', 'never', 'happen', 'again', 'i', 'called', 'for', 'an', 'independent', 'katrina', 'commission', 'because', 'it', 'is', 'simply', 'not', 'appropriate', 'for', 'government', 'to', 'investigate', 'itself', 'if', 'we', 'are', 'truly', 'going', 'to', 'provide', 'the', 'people', 'in', 'the', 'gulf', 'and', 'all', 'americans', 'with', 'the', 'answers', 'they', 'deserve', 'we', 'need', 'an', 'independent', 'commission', 'free', 'of', 'partisan', 'politics', 'it', 'is', 'also', 'important', 'that', 'congress', 'not', 'be', 'distracted', 'from', 'the', 'task', 'at', 'hand', 'making', 'sure', 'that', 'our', 'fellow', 'citizens', 'get', 'all', 'the', 'help', 'they', 'need', 'as', 'they', 'recover', 'and', 'rebuild', 'what', 'happened', 'today', 'on', 'the', 'senate', 'floor', 'is', 'the', 'same', 'thing', 'that', 'happened', 'four', 'years', 'ago', 'when', 'our', 'nation', 'was', 'desperately', 'searching', 'for', 'answers', 'after', '9', '11', 'urgent', 'calls', 'for', 'an', 'independent', 'commission', 'were', 'repeatedly', 'ignored', 'but', 'the', 'american', 'people', 'did', 'not', 'fall', 'silent', 'they', 'continued', 'to', 'demand', 'action', 'and', 'eventually', 'the', 'administration', 'relinquished', 'its', 'opposition', 'to', 'the', '9', '11', 'commission', 'and', 'our', 'nation', 'was', 'well', 'served', 'by', 'the', 'commission', 's', 'work', 'on', 'behalf', 'of', 'the', 'people', 'of', 'the', 'gulf', 'who', 'i', 'visited', 'with', 'last', 'week', 'in', 'houston', 'and', 'all', 'americans', 'who', 'are', 'demanding', 'answers', 'i', 'will', 'continue', 'to', 'fight', 'for', 'the', 'creation', 'of', 'the', 'katrina', 'commission', 'i', 'firmly', 'believe', 'that', 'we', 'need', 'to', 'look', 'back', 'to', 'see', 'what', 'went', 'wrong', 'so', 'we', 'can', 'move', 'forward', 'and', 'do', 'better', 'only', 'through', 'an', 'independent', 'katrina', 'commission', 'will', 'we', 'be', 'able', 'to', 'know', 'that', 'no', 'storm', 'or', 'no', 'act', 'of', 'terrorism', 'will', 'ever', 'again', 'leave', 'us', 'so', 'unable', 'to', 'respond', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Deep Neural Nets\n",
    "\n",
    "A popular, simplified package for introducing deep neural networks is [Keras](https://keras.io). It is a high level package in that we don't bother with every detail or hyper-parameter associated with the neural network (e.g., regularizers), and can stack on layers directly. For a rapid tutorial on neural networks for text such as the LSTM or the Recurrent Neural Network, Colah's blog is a great start. [LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) is an article on LSTMs, and if you'd like to  learn about RNN, Andrej Karpathy does a great job in [this blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), in addition to our reading from the newest online verion of Jurafsky & Martin's review of deep learning methods in their book on speech and language processing, chapters [6,7,9,10](https://web.stanford.edu/~jurafsky/slp3/), and the [*Deep Learning*](https://www.deeplearningbook.org/) book by Goodfellow, Bengio & Courville.\n",
    "\n",
    "In the following cells we build a basic deep net that has an embedding layer and an LSTM to perform classification. This is to illustrate the process of using Keras, which is a very popular library for such work. It may not yield state of the art performance because it constrains the hyperparameters you can tune, but is nonetheless an useful tool and works well on some datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_in_size = tokenizer.vocab_size\n",
    "embedding_dim = 32\n",
    "unit = 100\n",
    "no_labels = len(np.unique(train_labels))\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 128, 32)           976704    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,030,106\n",
      "Trainable params: 1,030,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm.add(LSTM(unit))\n",
    "model_lstm.add(Dense(no_labels, activation='softmax'))\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.6754 - accuracy: 0.6316\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.6162 - accuracy: 0.6372\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.2212 - accuracy: 0.8905\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0810 - accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0404 - accuracy: 0.9934\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0318 - accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0236 - accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0144 - accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(train_inputs, train_labels, \n",
    "                              epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of this model isn't terrible, but it still hovers around 70%. Below there is code for a slightly modified neural network - how does this one perform? Note that in this model, I have added another LSTM layer. You are encouraged to explore the [Keras documentaion](https://keras.io/layers/about-keras-layers/) to explore what kind of layers you can add and how they change performances for different tasks. Different kinds of losses, optimizers, activations and layers can change the flavour of your net dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.6651 - accuracy: 0.6261\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.2644 - accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0933 - accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0922 - accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0849 - accuracy: 0.9834\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0856 - accuracy: 0.9834\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0792 - accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 2s 3ms/step - loss: 0.0771 - accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "model_lstm2 = Sequential()\n",
    "model_lstm2.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm2.add(LSTM(unit))\n",
    "model_lstm2.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_lstm2 = model_lstm2.fit(train_inputs, train_labels, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9351769924163819"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sum(history_lstm2.history.get('accuracy'))/len(history_lstm2.history.get('accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On with BERT!\n",
    "\n",
    "So while Neural Networks can do a good job with some kind of classification tasks, they don't perform too well on intent classification. Let us see how a bidirectional transformer embedding like BERT might do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Models\n",
    "\n",
    "### Train Model\n",
    "Now that our input data is properly formatted, it's time to fine tune the BERT model.\n",
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\n",
    "We'll load BertForSequenceClassification. This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
    "\n",
    "### Structure of Fine-Tuning Model\n",
    "\n",
    "As we've showed beforehand, the first token of every sequence is the special classification token ([CLS]). Unlike the hidden state vector corresponding to a normal word token, the hidden state corresponding to this special token is designated by the authors of BERT as an aggregate representation of the whole sentence used for classification tasks. As such, when we feed in an input sentence to our model during training, the output is the length 768 hidden state vector corresponding to this token. The additional layer that we've added on top consists of untrained linear neurons of size [hidden_state, number_of_labels], so [768,2], meaning that the output of BERT plus our classification layer is a vector of two numbers representing the \"score\" for \"grammatical/non-grammatical\" that are then fed into cross-entropy loss.\n",
    "\n",
    "### The Fine-Tuning Process\n",
    "\n",
    "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task.\n",
    "Sometimes practicioners will opt to \"freeze\" certain layers when fine-tuning, or to apply different learning rates, apply diminishing learning rates, etc. all in an effort to preserve the good quality weights in the network and speed up training (often considerably). In fact, recent research on BERT specifically has demonstrated that freezing the majority of the weights results in only minimal accuracy declines, but there are exceptions and broader rules of transfer learning that should also be considered. For example, if your task and fine-tuning dataset is very different from the dataset used to train the transfer learning model, freezing the weights may not be a good idea. OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "Credit to Michel Kana's [tutorial](https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03) and the [tutorial](https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=GuE5BqICAne2) by Chris McCormick and Nick Ryan who describe the workings of BERT and the way it is used by the ```transformers``` package. \n",
    "\n",
    "## WARNING: SHIFT TO A GPU ENABLED MACHINE (e.g., Google Colab)\n",
    "\n",
    "Note that you only want to run the following code if you have a GPU. Otherwise, rerun the **same** cells we just ran on the Colab file to train your model, download it to your local, and load it by running\n",
    "```model = BertForSequenceClassification.from_pretrained(\"my_model_directory\", num_labels=2)```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"./senate\", num_labels=2)\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following cell can take upto 12 hours or longer if run without a GPU. The [Colab file](https://colab.research.google.com/drive/1_G6iGqiXb-zPBTurRxd7cgGrXyNaKGsA) demonstrates how to fine-tune models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COME BACK TO THIS NOTEBOOK to load and work with your trained model\n",
    "\n",
    "Once you tune your model on Colab (or on your own machine if you decided to do that instead), you load it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('./senate', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3398 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1804 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (922 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2178 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1874 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2012 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1806 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "# df = pd.read_csv(\"../../data/cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "df = pd.read_csv('./senate/senate_test.csv')\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 495 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 181 of 495 (36.57%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good performance. Note that we used [Matthews Correlation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) to meausure this. It ranges from -1 to 1, with +1 being the best. The Google BERT model has a similar score too, so this model performed quite well. It took a long time though, approximately a day with no GPU. It would be significantly faster if a CUDA enabled machine ran this. Hence, we recommend that you run this on the Collab notebook.\n",
    "\n",
    "The following lines save the model to disk, if you would like to: note that we ran this in the colab file to save it to disk there as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that estimate a deep classification model with Keras (and LSTM) and also BERT in order to predict pre-established data labels relevant to your final project (as for week 3's homework). Which works better? Are the errors the same or different?\n",
    "\n",
    "<span style=\"color:red\">***Stretch***</span>: <span style=\"color:red\">Now alter the neural network by stacking network layers, adjusting the embedding dimension, compare its performance with your model above, and interpret why it might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I used the ObamaClintonSandersReleases dataset to classify Obama (1) or not Obama (0). The entire file was split into two parts: training (2/3) and testing (1/3). The relevant files are stored in the `senate` directory. Pretrained model files are saved in the same location. The code above has been altered to read from the split data files and saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM\n",
    "\n",
    "Both LSTM models had over 90% accuracy. The model with the sigmoid activation function (lstm2) reported 2.4% higher  accuracy than the model using softmax. The average accuracy for both models is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy of lstm: 0.911\n",
      "Avg Accuracy of lstm2: 0.935\n"
     ]
    }
   ],
   "source": [
    "print('Avg Accuracy of lstm: %.3f' % (sum(history_lstm.history.get('accuracy'))/len(history_lstm.history.get('accuracy'))))\n",
    "print('Avg Accuracy of lstm2: %.3f' % (sum(history_lstm2.history.get('accuracy'))/len(history_lstm2.history.get('accuracy'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT\n",
    "\n",
    "The BERT model showed a huge improvement over LSTM with the model acheiving 100% accuracy on the 181 positive instances in the test data. It's difficult to determine the difference in errors between BERT and LSTM due to BERT'S perfect classification in this case. The code below reports the number of positive samples and MCC score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 181 of 495 (36.57%)\n",
      "MCC: 1.000\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings, Context Words\n",
    "\n",
    "We saw how a bootstrapped BERT model performed so much better than a model trained from scatch. Because BERT's method of capturing context is bidirectional, meaning that words can now have different word embedding values based on their location within a sentence. Let us use the same BERT model to capture sentence and word embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the sentence format for the BERT model, as well as how our vocabulary looks like. Note that you have to use the BERT tokenizer to use the BERT model because of the similar vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTS model uses a WordPiece technique to do its tokenizing, as described in the paper. That's why the word embedding is split up the way it is.\n",
    "A quick peek at what the voabulary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peninsula',\n",
       " 'adults',\n",
       " 'novels',\n",
       " 'emerged',\n",
       " 'vienna',\n",
       " 'metro',\n",
       " 'debuted',\n",
       " 'shoes',\n",
       " 'tamil',\n",
       " 'songwriter',\n",
       " 'meets',\n",
       " 'prove',\n",
       " 'beating',\n",
       " 'instance',\n",
       " 'heaven',\n",
       " 'scared',\n",
       " 'sending',\n",
       " 'marks',\n",
       " 'artistic',\n",
       " 'passage',\n",
       " 'superior',\n",
       " '03',\n",
       " 'significantly',\n",
       " 'shopping',\n",
       " '##tive',\n",
       " 'retained',\n",
       " '##izing',\n",
       " 'malaysia',\n",
       " 'technique',\n",
       " 'cheeks']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[6000:6030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indices.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment ID\n",
    "\n",
    "BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences. That is, for each token in â€œtokenized_text,â€ we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s). For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.\n",
    "\n",
    "If you want to process two sentences, assign each word in the first sentence plus the â€˜[SEP]â€™ token a 0, and all tokens of the second sentence a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did for classification, we now convert these segments to tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer is the hidden state layer, and this is what we pick up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model_embedding = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_embedding(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "          [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "          [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "          ...,\n",
       "          [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "          [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "          [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.6031, -0.3342, -0.7174,  0.3347,  0.5145, -0.1722,  0.4502,  0.2768,\n",
       "          -0.3769, -0.9998, -0.3657,  0.7535,  0.9817, -0.0192,  0.7959, -0.3459,\n",
       "          -0.1338, -0.3026,  0.1097,  0.5836,  0.5736,  0.9999,  0.1798,  0.1845,\n",
       "           0.2250,  0.9109, -0.5653,  0.8616,  0.8994,  0.7423, -0.2525,  0.0394,\n",
       "          -0.9894, -0.1331, -0.7763, -0.9826,  0.2223, -0.6115,  0.1941,  0.0177,\n",
       "          -0.7634,  0.2312,  0.9999, -0.7000,  0.4623, -0.2202, -1.0000,  0.1908,\n",
       "          -0.8150,  0.6483,  0.5878,  0.8198,  0.1014,  0.3185,  0.3963, -0.3216,\n",
       "          -0.1701,  0.0588, -0.1544, -0.4987, -0.5284,  0.1228, -0.4823, -0.7788,\n",
       "           0.6954,  0.0891, -0.0855, -0.1500,  0.0390, -0.0760,  0.6154,  0.2662,\n",
       "          -0.0129, -0.7253,  0.1352,  0.2921, -0.5613,  1.0000,  0.1536, -0.9681,\n",
       "           0.7166,  0.2600,  0.4519,  0.5470, -0.2798, -1.0000,  0.3419, -0.2645,\n",
       "          -0.9863,  0.1263,  0.5249, -0.2000,  0.5980,  0.4752, -0.2355, -0.4808,\n",
       "          -0.3786, -0.7284, -0.0909,  0.0124, -0.0689, -0.2531, -0.1324, -0.2361,\n",
       "           0.1732, -0.3216, -0.0188,  0.2302, -0.3221,  0.4996,  0.4346, -0.1935,\n",
       "           0.2968, -0.9292,  0.5326, -0.3695, -0.9876, -0.4770, -0.9902,  0.6349,\n",
       "          -0.1863, -0.2612,  0.9123, -0.1930,  0.3110,  0.0803, -0.7598, -1.0000,\n",
       "           0.0292, -0.0628, -0.1086, -0.2135, -0.9671, -0.9521,  0.3334,  0.8675,\n",
       "           0.2254,  0.9995, -0.2908,  0.9420,  0.0336, -0.4542,  0.4123, -0.4455,\n",
       "           0.4558, -0.4442, -0.0685,  0.3043,  0.0575,  0.1843, -0.6577, -0.3121,\n",
       "          -0.1069, -0.7729, -0.2328,  0.9032, -0.4681, -0.5580,  0.3359, -0.1644,\n",
       "          -0.1572,  0.6441,  0.2810,  0.2651,  0.1532,  0.4485, -0.5299,  0.2616,\n",
       "          -0.7413, -0.0347,  0.2560, -0.2659, -0.6092, -0.9868, -0.2346,  0.4682,\n",
       "           0.9771,  0.5646,  0.2360,  0.4567, -0.2170,  0.1420, -0.9554,  0.9832,\n",
       "          -0.0935,  0.2621, -0.7901,  0.5758, -0.7642, -0.5362,  0.6374, -0.3891,\n",
       "          -0.6368, -0.0045, -0.2658, -0.1721, -0.7466,  0.4832, -0.3128, -0.2640,\n",
       "           0.0435,  0.8879,  0.5961,  0.2972,  0.0742,  0.3041, -0.7367, -0.2117,\n",
       "          -0.0500,  0.0825,  0.0273,  0.9870, -0.5612, -0.0353, -0.8011, -0.9833,\n",
       "          -0.1874, -0.7143,  0.0476, -0.4777,  0.4406, -0.7087, -0.3319,  0.1035,\n",
       "          -0.2959, -0.6915,  0.2840, -0.5485,  0.3292, -0.3018,  0.8687,  0.7867,\n",
       "          -0.5158, -0.2411,  0.9175, -0.7601, -0.6967, -0.0763, -0.1411,  0.6739,\n",
       "          -0.6006,  0.9645,  0.6723,  0.3451, -0.9112, -0.6897, -0.3042, -0.0059,\n",
       "          -0.0918, -0.6402,  0.5602,  0.3850,  0.2737,  0.7868, -0.4155,  0.8343,\n",
       "          -0.9288, -0.9377, -0.9803,  0.1936, -0.9873,  0.7978,  0.1702,  0.6547,\n",
       "          -0.3664, -0.3837, -0.9602,  0.2690,  0.0832,  0.8077, -0.5984, -0.5181,\n",
       "          -0.4783, -0.9236, -0.0773, -0.0542,  0.1906,  0.0659, -0.8882,  0.3529,\n",
       "           0.5142,  0.4257, -0.8504,  0.9686,  1.0000,  0.9745,  0.7975,  0.3701,\n",
       "          -0.9993, -0.9159,  0.9999, -0.9649, -1.0000, -0.8484, -0.5494,  0.2254,\n",
       "          -1.0000, -0.0892,  0.0449, -0.8989,  0.2432,  0.9673,  0.7904, -1.0000,\n",
       "           0.8539,  0.8224, -0.5027,  0.8026, -0.2741,  0.9723,  0.3954,  0.5613,\n",
       "          -0.2778,  0.4943, -0.7842, -0.5614, -0.4786, -0.7206,  0.9944, -0.0361,\n",
       "          -0.2827, -0.8623,  0.6206, -0.0204, -0.2777, -0.9243, -0.2374,  0.5576,\n",
       "           0.4833,  0.1621,  0.2181, -0.4744,  0.1432, -0.0688, -0.3646,  0.5594,\n",
       "          -0.8221, -0.1388,  0.5845, -0.0662,  0.0617, -0.9573,  0.9249, -0.4059,\n",
       "           0.5819,  1.0000,  0.8847, -0.6462,  0.4425,  0.1442,  0.2397,  1.0000,\n",
       "           0.3757, -0.9790, -0.5021,  0.5227, -0.4537, -0.4564,  0.9975, -0.1468,\n",
       "          -0.4530, -0.2211,  0.9849, -0.9892,  0.9874, -0.6354, -0.9533,  0.9617,\n",
       "           0.9100, -0.3272, -0.5809,  0.1221,  0.2137,  0.1775, -0.6459,  0.5595,\n",
       "           0.3555,  0.0030,  0.7183,  0.1490, -0.4345,  0.2424, -0.5088,  0.0014,\n",
       "           0.9025,  0.3578, -0.0445, -0.0357, -0.2723, -0.8130, -0.9344,  0.4227,\n",
       "           1.0000, -0.1721,  0.8243,  0.0665,  0.0115, -0.1497,  0.4186,  0.3168,\n",
       "          -0.3061, -0.5515,  0.7428, -0.7339, -0.9949,  0.1418,  0.0288,  0.1303,\n",
       "           0.9994,  0.6172,  0.1452,  0.4381,  0.9631, -0.0898, -0.1024,  0.3720,\n",
       "           0.9655, -0.2082,  0.4160,  0.2856, -0.4470, -0.0806, -0.5101, -0.1494,\n",
       "          -0.8861,  0.3496, -0.9617,  0.9112,  0.9032,  0.4198,  0.1110,  0.5989,\n",
       "           1.0000, -0.9781,  0.0478,  0.8043, -0.0370, -0.9994, -0.4571, -0.3764,\n",
       "          -0.0341, -0.3013,  0.0021,  0.1011, -0.9597,  0.1910,  0.7922, -0.5135,\n",
       "          -0.9862,  0.0285,  0.4023,  0.2365, -0.9728, -0.3717, -0.4726,  0.2997,\n",
       "          -0.0355, -0.9264,  0.3197, -0.3812,  0.3245, -0.1921,  0.4575,  0.3563,\n",
       "           0.9515, -0.8870, -0.3251, -0.1148, -0.6957,  0.4810, -0.2975, -0.7607,\n",
       "          -0.1648,  1.0000, -0.4754,  0.5410,  0.3828,  0.1635, -0.2463,  0.1942,\n",
       "           0.8299,  0.1894,  0.0875, -0.6173,  0.7333, -0.2475,  0.3843,  0.7312,\n",
       "          -0.0760,  0.6759,  0.7408,  0.1733,  0.0710,  0.0930,  0.9232, -0.0188,\n",
       "          -0.2704, -0.3332, -0.0659, -0.3261,  0.7431,  1.0000,  0.1622,  0.5590,\n",
       "          -0.9939, -0.7758, -0.7434,  1.0000,  0.8649, -0.6865,  0.5643,  0.4938,\n",
       "          -0.2507, -0.0745, -0.1468, -0.2566,  0.2531,  0.0162,  0.9603, -0.5751,\n",
       "          -0.9828, -0.4233,  0.3365, -0.9327,  0.9997, -0.5279, -0.2036, -0.2868,\n",
       "          -0.4147, -0.9348, -0.0477, -0.9812, -0.1836,  0.1210,  0.9609,  0.2963,\n",
       "          -0.4743, -0.7886,  0.8539,  0.4805, -0.8080, -0.9297,  0.9734, -0.8989,\n",
       "           0.3318,  1.0000,  0.4983,  0.0046,  0.1519, -0.2174,  0.3163, -0.3975,\n",
       "           0.5479, -0.9144, -0.0836, -0.1866,  0.3943, -0.1005, -0.9010,  0.5822,\n",
       "           0.0541, -0.4141, -0.4825, -0.0623,  0.3400,  0.6302, -0.1646, -0.0293,\n",
       "           0.1773,  0.0035, -0.7814, -0.2836, -0.3813, -0.9999,  0.5009, -1.0000,\n",
       "           0.6917, -0.3492, -0.2238,  0.7105,  0.8107,  0.7481, -0.4549, -0.4793,\n",
       "           0.7201,  0.6103, -0.1528, -0.2139, -0.4457,  0.2485,  0.0196,  0.1607,\n",
       "          -0.3812,  0.5145, -0.2807,  1.0000,  0.0829, -0.3200, -0.5929,  0.2053,\n",
       "          -0.2679,  1.0000, -0.2241, -0.9651,  0.1681, -0.5537, -0.5055,  0.4764,\n",
       "          -0.0439, -0.7710, -0.8442,  0.7623,  0.3223, -0.5828,  0.5065, -0.2420,\n",
       "          -0.2434, -0.0287,  0.8268,  0.9844,  0.8406,  0.3518, -0.9611, -0.3503,\n",
       "           0.9309,  0.1013, -0.1565, -0.0012,  1.0000,  0.4139, -0.7002,  0.0942,\n",
       "          -0.8437, -0.2698, -0.7333,  0.2633,  0.0600,  0.9015, -0.2510,  0.9170,\n",
       "          -0.7876, -0.0735, -0.5044,  0.2206,  0.2786, -0.8753, -0.9837, -0.9885,\n",
       "           0.5545, -0.2806, -0.0823,  0.3698,  0.1557,  0.2687,  0.4354, -1.0000,\n",
       "           0.9126,  0.3169,  0.7036,  0.9720,  0.4816,  0.6401,  0.3309, -0.9813,\n",
       "          -0.6150, -0.3007, -0.1601,  0.3913,  0.3273,  0.6264,  0.2662, -0.3612,\n",
       "          -0.6613, -0.3084, -0.9703, -0.9852,  0.3886,  0.0251, -0.3822,  0.9373,\n",
       "          -0.0961,  0.0824,  0.4406, -0.5929,  0.1701,  0.6097,  0.1687, -0.0525,\n",
       "           0.5533,  0.8141,  0.7725,  0.9789, -0.7193,  0.2995, -0.5652,  0.3757,\n",
       "           0.9063, -0.9190,  0.0740,  0.3566, -0.1535,  0.1921, -0.1948, -0.4410,\n",
       "           0.9270, -0.0852,  0.3333, -0.2275,  0.1727, -0.3694, -0.1233, -0.7592,\n",
       "          -0.5162,  0.4856, -0.1530,  0.8161,  0.7259, -0.0103, -0.4483, -0.1682,\n",
       "           0.0424, -0.8891,  0.2156, -0.0442,  0.6451,  0.3764, -0.4232,  0.9787,\n",
       "          -0.0989, -0.3853, -0.3173, -0.5348,  0.5307, -0.6883, -0.3786, -0.4665,\n",
       "           0.7207,  0.3239,  0.9999, -0.5526, -0.4826, -0.3439, -0.3580,  0.1069,\n",
       "          -0.2620, -1.0000,  0.2673, -0.3037,  0.4706, -0.6132,  0.8511, -0.4910,\n",
       "          -0.7231, -0.1092,  0.5412,  0.5265, -0.4635, -0.2461,  0.4946, -0.3470,\n",
       "           0.9149,  0.5902, -0.1862,  0.7004,  0.5465, -0.2839, -0.5723,  0.6648]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0][0][0]), len(output[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "This kind of forward pass returns us the last layer of the net, which we will use to make our vectors. The first object returned contains the batch number, followed by each of the tokens and their vector values. The second object contains a vector value, which I suspect is the sentence vector of the tokens. \n",
    "\n",
    "The first index is the batch size, and our batch size is 1, so we just choose the 0th index and work with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, sentence_embedding = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4964, -0.1831, -0.5231,  ..., -0.1902,  0.3738,  0.3964],\n",
       "        [-0.1323, -0.2762, -0.3495,  ..., -0.4567,  0.3786, -0.1096],\n",
       "        [-0.3626, -0.4002,  0.0676,  ..., -0.3207, -0.2709, -0.3004],\n",
       "        ...,\n",
       "        [ 0.2961, -0.2856, -0.0382,  ..., -0.6056, -0.5163,  0.2005],\n",
       "        [ 0.4878, -0.0909, -0.2358,  ..., -0.0017, -0.5945, -0.2431],\n",
       "        [-0.2517, -0.3519, -0.4688,  ...,  0.2500,  0.0336, -0.2627]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s take a quick look at the range of values for a given layer and token.\n",
    "\n",
    "Youâ€™ll find that the range is fairly similar for all layers and tokens, with the majority of values falling between [-2, 2], and a small smattering of values around -10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = word_embeddings[0][0]\n",
    "vec = vec.detach().numpy()\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are grouped by layer - we can use the permute function to make it grouped by each individual token instead. Let us look at what the later looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors\n",
    "\n",
    "So each of those tokens have embedding values - let us try and compare them with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs = []\n",
    "# For each token in the sentence...\n",
    "for embedding in word_embeddings[0]:\n",
    "    cat_vec = embedding.detach().numpy()\n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.00105178e-01, -5.38040876e-01, -1.66908562e-01,  2.24162325e-01,\n",
       "        6.89657986e-01,  2.22385854e-01, -7.56619155e-01,  5.57399273e-01,\n",
       "       -1.16005346e-01, -6.20120645e-01,  2.00048819e-01, -6.10094607e-01,\n",
       "        1.40247405e-01,  5.32209098e-01, -1.21432531e+00, -1.06149554e-01,\n",
       "        4.02297899e-02,  6.42405868e-01,  7.80067861e-01,  2.75579154e-01,\n",
       "       -5.72042465e-01, -3.81739773e-02,  3.94061208e-01,  8.27549875e-01,\n",
       "        1.92855492e-01,  2.17229262e-01,  6.54001594e-01,  1.72798008e-01,\n",
       "        7.94579163e-02,  2.77848333e-01,  7.04422593e-01,  2.74361342e-01,\n",
       "        2.48815626e-01,  6.83146641e-02,  9.52315331e-02, -1.51546225e-01,\n",
       "       -4.54895586e-01,  2.62927115e-01, -6.88628495e-01,  4.48396325e-01,\n",
       "       -3.96416277e-01, -4.63360399e-01, -3.96804899e-01,  3.38887215e-01,\n",
       "       -1.51973039e-01, -8.69177803e-02, -5.62799931e-01,  2.22961232e-01,\n",
       "       -6.40250981e-01, -4.35119942e-02, -2.70755202e-01,  1.06316996e+00,\n",
       "       -1.36073220e+00, -7.31656075e-01, -3.90435085e-02,  6.49959028e-01,\n",
       "       -8.00228655e-01, -8.03872526e-01,  4.41913977e-02, -5.70225418e-01,\n",
       "        8.58783603e-01,  3.23224723e-01,  6.67016089e-01, -1.15356314e+00,\n",
       "       -2.20980793e-01, -5.66596925e-01,  6.44095778e-01,  1.33071125e-01,\n",
       "       -1.95376411e-01,  2.48074681e-01, -1.65709145e-02,  1.48688900e+00,\n",
       "       -8.89763236e-01, -8.26348722e-01,  1.14484549e-01,  5.21919370e-01,\n",
       "       -1.12809122e-01,  3.85486066e-01,  1.41850442e-01, -2.13631541e-01,\n",
       "       -2.29526505e-01, -3.91850948e-01, -2.97649115e-01,  2.35841632e-01,\n",
       "        1.49914712e-01, -1.13530315e-01,  4.27941203e-01,  2.72549897e-01,\n",
       "        1.90691546e-01,  4.44440335e-01, -2.24165857e-01,  4.18876112e-01,\n",
       "       -5.08873641e-01,  5.98854832e-02, -7.34089196e-01,  4.74217176e-01,\n",
       "       -2.44856670e-01,  9.47208479e-02, -4.98273045e-01,  1.25789806e-01,\n",
       "        1.62739992e-01, -1.44896293e+00,  6.53545260e-02,  3.54079574e-01,\n",
       "       -1.07342705e-01, -3.68617415e-01, -5.26663899e-01, -1.30093485e-01,\n",
       "       -4.46454793e-01,  8.12667459e-02,  7.59991467e-01, -6.53747559e-01,\n",
       "        1.23026110e-01, -8.28477502e-01,  7.96982422e-02, -3.80833715e-01,\n",
       "        5.93177199e-01, -1.10844409e+00, -2.33301967e-01, -8.39494705e-01,\n",
       "        3.38301212e-02,  6.68954372e-01,  4.05243039e-01,  1.18437660e+00,\n",
       "        1.15955293e-01,  2.88317740e-01, -1.28722548e-01,  8.46805155e-01,\n",
       "       -9.97752100e-02, -1.94156170e-03,  7.42848396e-01,  2.74241269e-01,\n",
       "       -4.89082456e-01, -1.63954765e-01,  5.10476828e-01,  2.24786013e-01,\n",
       "       -3.50530088e-01, -5.58640242e-01, -6.38005853e-01, -1.77038833e-03,\n",
       "        3.68091136e-01,  1.88445412e-02,  1.93027556e-02,  1.33949292e+00,\n",
       "        3.52082074e-01,  4.38397557e-01, -4.03664447e-02, -2.39110664e-01,\n",
       "       -5.38911484e-02,  4.56580132e-01,  2.20837146e-01,  2.14630961e-01,\n",
       "       -2.63621628e-01, -3.43714714e-01,  7.28081048e-01, -2.43926555e-01,\n",
       "       -8.36848736e-01,  1.77100837e-01, -4.70952004e-01, -8.96769613e-02,\n",
       "        2.90589064e-01,  1.67861700e-01,  1.82788566e-01,  1.72299132e-01,\n",
       "       -1.21507466e+00, -9.30918396e-01,  3.84655923e-01,  3.39226097e-01,\n",
       "       -7.33036339e-01, -2.99337149e-01, -1.02093369e-01, -2.80379891e-01,\n",
       "        6.76863253e-01,  1.00625172e-01,  8.85389268e-01,  3.22275907e-01,\n",
       "       -3.35391939e-01, -8.29100728e-01,  9.13234502e-02, -2.88453907e-01,\n",
       "        3.73798981e-02,  9.80299354e-01,  6.91520870e-01,  8.41403246e-01,\n",
       "        7.16992259e-01, -4.42527831e-01,  1.65952814e+00,  2.51317233e-01,\n",
       "        2.18893677e-01, -1.64816350e-01, -4.72294152e-01, -1.04751658e+00,\n",
       "       -2.76556671e-01,  1.41952217e-01, -2.90575355e-01, -3.56772780e-01,\n",
       "       -2.33660057e-01, -4.13504422e-01, -8.18977535e-01, -1.85785279e-01,\n",
       "       -3.12560350e-01, -1.49953201e-01, -4.99758124e-01, -1.77258044e-01,\n",
       "       -5.29543042e-01, -1.21574476e-03,  8.82899389e-02,  4.79216874e-01,\n",
       "        7.67927945e-01,  5.76780476e-02, -1.11864842e-01,  1.26531601e-01,\n",
       "       -3.25565279e-01,  5.45318365e-01, -3.57872903e-01,  4.68552172e-01,\n",
       "       -3.62120092e-01, -8.18756223e-01, -2.14384243e-01, -1.82899147e-01,\n",
       "       -3.47012997e-01, -1.06688634e-01, -1.06496871e-01,  3.63481641e-01,\n",
       "       -1.47270113e-01,  6.45162463e-01,  5.89665532e-01, -4.17156994e-01,\n",
       "       -6.88160241e-01,  5.54796219e-01, -4.02300864e-01,  6.51016057e-01,\n",
       "        5.59804738e-01, -2.65119344e-01,  4.05280292e-01, -1.10231273e-01,\n",
       "       -1.41866362e+00,  4.05817442e-02, -4.75457422e-02,  3.85531217e-01,\n",
       "       -3.76613379e-01,  2.83511877e-01,  6.74494028e-01, -3.61923039e-01,\n",
       "        2.65550911e-01,  5.47320604e-01, -1.70675576e-01, -3.37475479e-01,\n",
       "       -7.50809073e-01,  6.10518306e-02, -3.81847799e-01, -5.75955808e-01,\n",
       "       -7.95301139e-01, -5.25467813e-01,  6.17609739e-01, -1.01236701e-01,\n",
       "        1.35086462e-01, -2.15505749e-01, -6.61384344e-01,  4.59290445e-01,\n",
       "        1.07030797e+00,  3.53024095e-01, -2.41710424e-01,  2.70300925e-01,\n",
       "       -4.17082101e-01, -7.04693377e-01,  2.70743310e-01,  6.67345822e-01,\n",
       "        1.63488939e-01,  6.60553277e-01,  3.35989535e-01,  5.88464737e-01,\n",
       "       -2.10436098e-02,  1.33238900e+00,  4.92879421e-01, -2.17822090e-01,\n",
       "       -7.85797164e-02, -3.59966164e-03,  5.89243293e-01,  6.38868570e-01,\n",
       "        2.77977675e-01,  4.18110013e-01,  8.07805806e-02, -5.12331963e-01,\n",
       "        4.21021283e-01, -2.81427324e-01,  9.39152837e-02,  1.68198538e+00,\n",
       "       -2.74344146e-01, -6.18796945e-01, -1.09555013e-03,  1.05944760e-02,\n",
       "       -2.37376153e-01, -5.01427054e-02, -1.32540613e-01,  3.69526803e-01,\n",
       "        5.35571992e-01,  1.59625828e+00,  7.92906582e-01, -1.84033662e-01,\n",
       "        5.90657651e-01, -2.91540772e-02,  4.09777462e-01, -5.58120847e-01,\n",
       "       -5.50519705e-01,  3.30812722e-01, -1.18630558e-01, -3.26503724e-01,\n",
       "       -3.86814165e+00,  1.63464105e+00,  1.90309510e-01, -4.96690005e-01,\n",
       "        3.87484908e-01,  1.23670071e-01,  1.98889524e-01, -4.27615166e-01,\n",
       "       -9.81272221e-01,  1.11503437e-01, -6.32436693e-01, -7.35416949e-01,\n",
       "        6.65505707e-01, -1.00418240e-01, -6.15369119e-02, -8.10043991e-01,\n",
       "       -2.32270062e-01,  3.20774406e-01, -6.55882508e-02,  2.98217982e-02,\n",
       "       -1.63735792e-01, -8.44664514e-01, -1.69554591e-01,  3.19487363e-01,\n",
       "        7.80971050e-01,  6.70378149e-01, -7.52065361e-01,  1.83807481e-02,\n",
       "        1.37383953e-01,  2.68975824e-01, -1.01248235e-01, -4.81866300e-04,\n",
       "       -1.05511965e-02,  8.16306546e-02, -8.51336792e-02, -5.49487948e-01,\n",
       "       -4.67553675e-01, -4.32047158e-01,  1.10501513e-01, -5.44905901e-01,\n",
       "        7.81930909e-02,  3.99505496e-01, -5.20846665e-01,  4.85510975e-01,\n",
       "        1.18812418e+00, -3.83662462e-01, -1.73490539e-01,  2.06929713e-01,\n",
       "       -4.43349108e-02,  6.68270648e-01,  2.48089597e-01, -2.21410275e-01,\n",
       "        1.19868927e-01, -1.88470930e-01,  3.71637583e-01,  6.68726563e-01,\n",
       "       -4.86612581e-02,  3.64500701e-01,  4.55018163e-01, -3.20631504e-01,\n",
       "       -4.72919345e-01, -2.96709500e-02,  2.69895256e-01, -9.94013101e-02,\n",
       "       -1.15201019e-01, -1.42618954e-01, -1.35905814e+00, -6.30065501e-01,\n",
       "        6.43828809e-02, -2.95721829e-01, -2.28575110e-01,  3.21616024e-01,\n",
       "       -1.23957708e-01, -1.16941178e+00, -1.17050618e-01, -4.22401220e-01,\n",
       "        9.00172472e-01, -6.32592976e-01, -5.31062245e-01,  3.78948867e-01,\n",
       "        6.58740222e-01, -8.63100961e-03,  3.94772083e-01, -7.59804100e-02,\n",
       "        2.31093585e-01,  1.66627288e-01, -4.36976194e-01,  5.68560302e-01,\n",
       "       -1.27302217e+00, -6.08598948e-01,  8.54590356e-01,  1.34382296e+00,\n",
       "        1.65091872e-01, -7.12925613e-01,  1.78784341e-01,  2.45697454e-01,\n",
       "       -5.30435205e-01, -1.01865172e-01,  4.33438540e-01, -5.01179546e-02,\n",
       "       -1.30878836e-01,  7.03382611e-01,  9.09214675e-01, -2.18904048e-01,\n",
       "       -4.87017393e-01, -4.50665772e-01, -1.58164024e-01, -3.78564894e-01,\n",
       "       -1.17219853e+00,  1.18384886e+00,  6.85410678e-01, -8.34445775e-01,\n",
       "        9.68693614e-01, -6.04529500e-01, -1.54704064e-01,  5.65996528e-01,\n",
       "        1.88354641e-01, -4.36000705e-01,  2.00647786e-01, -3.38782907e-01,\n",
       "       -5.27548373e-01,  3.11734885e-01, -7.68792272e-01, -1.26127374e+00,\n",
       "        2.90919244e-02,  2.39797905e-01, -1.57006651e-01, -4.30590183e-01,\n",
       "       -4.04360294e-01, -3.43982130e-01,  6.21457040e-01, -2.54160941e-01,\n",
       "       -3.09357524e-01,  6.39529526e-01,  5.32336056e-01,  3.54171582e-02,\n",
       "        5.13361394e-01, -6.62259638e-01, -2.23097205e-01, -3.55829820e-02,\n",
       "        8.64466280e-02,  5.70088446e-01, -1.83757737e-01, -5.24601817e-01,\n",
       "       -2.06634760e-01, -4.60808337e-01, -5.68815589e-01,  2.60166734e-01,\n",
       "        2.69004703e-01, -3.84126782e-01, -3.31551671e-01,  9.85261351e-02,\n",
       "        4.19178426e-01, -5.71831822e-01,  4.81580973e-01,  1.04656935e+00,\n",
       "        1.00244677e+00, -3.44642073e-01, -7.91853368e-01, -7.36882269e-01,\n",
       "        3.38768601e-01, -3.19743007e-01,  1.11951733e+00,  2.24745363e-01,\n",
       "       -1.57896233e+00,  2.97900498e-01, -1.16091943e+00, -3.10249507e-01,\n",
       "       -3.35870266e-01,  6.65818393e-01,  1.87726125e-01, -5.02575934e-01,\n",
       "        6.12166673e-02,  3.58348459e-01, -3.81596446e-01,  5.85074365e-01,\n",
       "        9.56159830e-02, -8.22306991e-01,  4.21911739e-02,  3.18865210e-01,\n",
       "       -2.58248240e-01,  6.93809867e-01,  3.79529297e-01, -3.86273712e-01,\n",
       "        3.90699804e-01,  7.65455306e-01,  4.24310744e-01,  7.28108168e-01,\n",
       "       -2.09065512e-01, -1.44901097e-01, -5.57259560e-01,  7.36228049e-01,\n",
       "        2.83446200e-02,  2.54720926e-01, -8.06537032e-01, -8.30433011e-01,\n",
       "        2.30393186e-01,  3.90536308e-01,  9.75995809e-02,  3.05732906e-01,\n",
       "       -7.09479272e-01,  2.50360548e-01, -3.81978974e-02, -2.47360438e-01,\n",
       "        1.58738464e-01, -1.52982771e-01,  3.16583961e-01,  2.41335347e-01,\n",
       "       -8.37051749e-01,  7.22557604e-01, -7.54664540e-01, -2.42479414e-01,\n",
       "       -1.30211568e+00, -6.12312436e-01,  3.88116300e-01, -5.23191273e-01,\n",
       "        4.24462855e-01,  1.01979427e-01, -2.95198441e-01, -1.26647919e-01,\n",
       "        5.61947897e-02, -1.17727958e-01, -4.64811474e-02, -3.39387447e-01,\n",
       "       -1.04287803e+00,  6.31195083e-02,  6.73450455e-02,  8.51049781e-01,\n",
       "       -4.52674538e-01,  3.81024241e-01, -1.93321198e-01, -6.73990726e-01,\n",
       "       -3.29325572e-02, -2.01821685e-01, -1.71536058e-01, -1.83924232e-02,\n",
       "       -1.91603616e-01, -1.76412678e+00,  3.09613049e-02, -3.42965901e-01,\n",
       "       -1.74448639e-01,  2.44461775e-01, -1.19383838e-02,  1.40699744e-03,\n",
       "        2.19213635e-01,  8.53772640e-01,  5.74283004e-01,  6.92721248e-01,\n",
       "        1.24103632e-02,  4.02480721e-01,  3.76083642e-01, -4.18242007e-01,\n",
       "       -1.07574292e-01,  2.45518565e-01, -8.73344898e-01,  6.11942768e-01,\n",
       "        3.25544327e-01,  2.30418146e-01, -1.33763418e-01,  4.97923702e-01,\n",
       "        3.39616150e-01, -7.34481990e-01, -4.37537938e-01,  2.55328834e-01,\n",
       "        4.32665497e-01,  2.80251533e-01,  2.70678222e-01,  6.21733904e-01,\n",
       "        5.28043568e-01, -3.18828493e-01,  1.06860375e+00, -1.39554787e+00,\n",
       "        3.96364927e-01, -3.17227304e-01, -3.41307580e-01,  8.98074687e-01,\n",
       "       -1.07135689e+00, -1.45772970e+00,  5.98420024e-01, -3.45193863e-01,\n",
       "       -5.42655945e-01,  5.87149501e-01,  8.47732350e-02, -5.85888550e-02,\n",
       "        4.51142527e-02, -1.02018766e-01, -8.17145288e-01,  1.72698200e-02,\n",
       "       -4.79705900e-01, -1.04606450e+00,  6.69432163e-01,  1.19788803e-01,\n",
       "        3.58919024e-01, -1.90276936e-01, -2.93921947e-01,  9.13357735e-01,\n",
       "        4.90855753e-01,  1.79602653e-01,  4.48663831e-01,  5.82656801e-01,\n",
       "        2.79100925e-01, -2.66172469e-01,  4.10100222e-01,  4.22274947e-01,\n",
       "        2.82040656e-01, -1.40471309e-02, -4.52582598e-01, -1.30246684e-01,\n",
       "       -9.36193466e-02, -2.60851234e-01, -6.49596214e-01, -1.54569173e+00,\n",
       "        5.82297742e-01,  8.07848334e-01, -1.28410149e+00, -2.06774697e-02,\n",
       "       -1.22055426e-01, -5.36682248e-01, -9.02507901e-01, -6.58406168e-02,\n",
       "       -3.76136750e-01,  3.10067117e-01,  3.17422569e-01,  3.84058088e-01,\n",
       "       -1.04566485e-01,  4.31201965e-01,  1.08326942e-01, -3.28217208e-01,\n",
       "        2.21488312e-01,  3.67119372e-01, -5.36320627e-01,  1.09050572e+00,\n",
       "       -5.63834488e-01,  1.81655094e-01,  3.46098185e-01,  1.38984963e-01,\n",
       "       -4.30902392e-01, -3.11836839e-01,  3.10479254e-01, -5.01188338e-01,\n",
       "        7.43191019e-02, -6.06038451e-01,  4.48144563e-02,  1.77744627e+00,\n",
       "        1.98232412e-01, -1.46390185e-01, -8.00529793e-02, -2.82063156e-01,\n",
       "        6.54861569e-01,  1.05088234e+00, -7.70301670e-02, -1.70815438e-01,\n",
       "       -7.92370856e-01, -8.94895732e-01,  5.78312218e-01,  4.91952777e-01,\n",
       "        2.35983849e-01,  1.30941063e-01, -1.84942514e-01,  3.88252020e-01,\n",
       "       -1.75990567e-01, -1.08280167e-01,  4.07038689e-01, -3.59313726e-01,\n",
       "       -1.13180660e-01,  6.76867366e-01, -3.97601634e-01, -7.24804521e-01,\n",
       "       -7.31622502e-02, -2.29115739e-01, -3.11556637e-01, -2.55984426e-01,\n",
       "        5.45633316e-01,  6.01333618e-01, -5.57293221e-02,  2.77657628e-01,\n",
       "       -1.09326744e+00,  6.09708726e-01,  3.13963652e-01, -7.14489281e-01,\n",
       "       -2.08376169e-01, -6.81147516e-01, -5.39769828e-01, -5.48418522e-01,\n",
       "       -5.35424829e-01, -4.06682491e-01,  5.89736044e-01,  1.54623568e-01,\n",
       "       -2.18063034e-02, -7.23221242e-01,  7.95892358e-01,  2.51649544e-02,\n",
       "        1.68416530e-01,  3.17795396e-01,  4.78339970e-01, -8.10776830e-01,\n",
       "        3.85684371e-01,  4.61336195e-01,  4.91644830e-01,  4.98538911e-02,\n",
       "        8.80058110e-01, -4.29164946e-01,  1.07386053e-01, -3.75227451e-01,\n",
       "        1.04665376e-01,  9.05810297e-02,  4.33465302e-01, -2.32117519e-01,\n",
       "       -5.39758563e-01,  2.20032752e-01, -4.52381343e-01, -6.18497469e-02,\n",
       "       -5.02074718e-01,  7.54833698e-01, -4.75620866e-01, -7.47429073e-01,\n",
       "        2.14901283e-01,  1.20064832e-01, -1.89599514e-01,  1.88413888e-01,\n",
       "       -2.42248178e-01, -1.23438597e-01,  1.42908260e-01, -1.13749653e-01,\n",
       "       -4.95990634e-01, -3.27722192e-01, -7.45417923e-03, -2.51940250e-01,\n",
       "       -4.27870639e-02,  4.06990677e-01, -4.53232467e-01,  1.85445592e-01,\n",
       "        6.37527227e-01,  9.83269215e-01, -2.47057229e-02, -4.18327987e-01,\n",
       "        2.78188527e-01,  2.92034656e-01, -6.46762490e-01, -2.31634211e-02,\n",
       "        9.07084703e-01,  1.26524836e-01, -4.15353626e-01,  4.89726722e-01,\n",
       "        9.33253884e-01, -6.09263256e-02, -4.41537023e-01, -4.37460005e-01,\n",
       "       -3.51203740e-01,  5.29220998e-01, -2.96276748e-01, -1.99333906e-01,\n",
       "       -9.81933624e-02, -3.97102445e-01,  5.62380813e-02, -6.58384204e-01,\n",
       "       -1.49604782e-01, -3.76192853e-04, -2.25457937e-01,  3.87611747e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_vecs)\n",
    "# token_vecs[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to create the vectors is to sum the last four layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vector\n",
    "\n",
    "To get a single vector for our entire sentence we have multiple application-dependent strategies - we could just average all the tokens in our sentence. We can also use this oppurtunity to see if the second vector returned is a sentence vector too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_0 = sentence_embedding.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding_1 = np.mean(token_vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embedding_0), len(sentence_embedding_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the power of these vectors is how they are context dependant - our sentence had multiple uses of the word bank. Let us see the index and the word of the sentence and check the context accordingly. We'll then print the simlarity values for the similar and different meanings and see how it turns out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"bank\".\n",
      "\n",
      "bank vault    [ 0.9001052  -0.5380409  -0.16690856  0.22416233  0.689658  ]\n",
      "bank robber   [ 0.7977135  -0.52172714 -0.19837019  0.18898587  0.59409297]\n",
      "river bank    [ 0.29608953 -0.2856337  -0.0381838   0.16736254  0.7712633 ]\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.95\n",
      "Vector similarity for *different* meanings:  0.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs[10], token_vecs[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs[10], token_vecs[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense! Let us see if the mean value of all the tokens and what we think is the sentence vector is the same thing, by checking their cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008313147351145744"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cosine(sentence_embedding_0, sentence_embedding_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is good - it seems it is indeed the sentence vector, so we can now write two functions which calculate the word and sentence vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_10 = word_vector(text, 6, model_embedding, tokenizer)\n",
    "word_6 = word_vector(text, 10, model_embedding, tokenizer)\n",
    "word_19 = word_vector(text, 19, model_embedding, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(text, model, tokenizer, method=\"average\"):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)\n",
    "    token_vecs = []\n",
    "    \n",
    "    for embedding in word_embeddings[0]:\n",
    "        cat_vec = embedding.detach().numpy()\n",
    "        token_vecs.append(cat_vec)\n",
    "        \n",
    "    if method == \"average\":\n",
    "        sentence_embedding = np.mean(token_vecs, axis=0)\n",
    "    if method == \"model\":\n",
    "        sentence_embedding = sentence_embeddings\n",
    "    # do something\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vec_0 = sentence_vector(text, model_embedding, tokenizer)\n",
    "sen_vec_1 = sentence_vector(text, model_embedding, tokenizer, method=\"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics\n",
    "It is worth noting that word-level similarity comparisons are not appropriate with BERT embeddings because these embeddings are contextually dependent, meaning that the word vector changes depending on the sentence it appears in. This enables direct sensitivity to polysemy so that, e.g., your representation encodes river â€œbankâ€ and not a financial institution â€œbankâ€. Nevertheless, it makes direct word-to-word similarity comparisons less valuable. For sentence embeddings, however, similarity comparison is still valid such that one can query, for example, a single sentence against a dataset of other sentences in order to find the most similar. Depending on the similarity metric used, the resulting similarity values will be less informative than the relative ranking of similarity outputs as some similarity metrics make assumptions about the vector space (equally-weighted dimensions, for example) that do not hold for our 768-dimensional vector space.\n",
    "\n",
    "### Using the Vectors\n",
    "\n",
    "Without fine-tuning, BERT features may be less useful than plain GloVe or word2vec.\n",
    "They start to be interesting when you fine-tune a classifier on top of BERT. \n",
    "\n",
    "### Using Transformers Pipelines\n",
    "\n",
    "The context vectors make the other pipeline functions which transformers has built in a lot more powerful. \n",
    "\n",
    "### NOTE\n",
    "The pipeline functionality in transformers is currently being worked on and might be broken, so it is an optional part of the exercise. Do try to uncomment the lines of code and try to see if it works, though! If you have managed to get transformers v2.5.1 installed, it will work - I managed to get it to work sometimes, it can be annoying to get it to work but when it works it works well.\n",
    "\n",
    "Consider the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62cca244c384590814872a142353200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate a pipeline for sentiment-analysis\n",
    "nlp_sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997735023498535}]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"This BERT model is so good at classifiying sentiment, I love it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a strong positive sentiment, which we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sentiment(\"I'm so sad that I have to spend this weekend just doing HW and readings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative label, bingo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e87644e53b4cc6ac38c6bce98195ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8b2d71699a4820a19b76f689ef20e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd07b66ba9964ee59ef18d7f779a7456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4b9c2c67774766bf5ecdd3e4877589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=473.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd72c626f4948b5b87ebda5a607827b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=260793700.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate a pipeline for question-answering\n",
    "nlp_question = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9860029072710859,\n",
       " 'start': 34,\n",
       " 'end': 64,\n",
       " 'answer': 'analysing complex textual data'}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_question({\n",
    "    'question': 'What is my favorite thing to do on weekends ?',\n",
    "    'context': 'There is nothing I like more than analysing complex textual data all weekend '\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also great at question-answering tasks!\n",
    "We can also extract features, as we manually did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9662004dad45ef90708e27632a2dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0824ce2343a749f488298bbc7d311619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_feature = pipeline('feature-extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "output = nlp_feature(\"Just sitting here exploring data all day long\")\n",
    "arr = np.array(output)\n",
    "len(arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.49644384"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huggingface/transformers repository lists the other pipeline functions, such as ner extraction, sequence classification, and masking. You are encouraged to explore them. \n",
    "https://github.com/huggingface/transformers#quick-tour-of-pipelines\n",
    "\n",
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, use the pipeline functions or the word or sentence vector functions (e.g., similarity) to explore the social game underlying the production and meaning of texts associated with your final project. You have used similar, but often weaker versions in previous weeks. How does BERT help you gain insight regarding your research question that is similar and different from prior methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I used COHA magazine articles from the year 1950. To limit the focus, I selected articles with the words \"immigrant\" or \"emmigrant\" in them. The goal here is to extract some information about the vector space surrounding these two terms in context. Previously, we did this with word2vec and TSNE projection. \n",
    "\n",
    "In the code below, I use the question answering pipeline to analyze the topic of immigration. The context for each question is the first 50k characters of the COHA text. The power of the BERT model is apparent in that it produced unique, sensible answers for who/where/why/how questions about immigration. \n",
    "\n",
    "Word2vec enabled us to manipulate the vector space to find the answer to analogies, but that required at least three vectors to describe (X-Y+Z). In the BERT case, we do no have this same constraint with questions, although we do continue think about the semantic space in high-demensions. Word2vec was more convenient for finding matching/dissimilar word vector, whereas BERT is better able to handle a variety of tasks like ner, sentiment analysis, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(751, 6)\n",
      "(11, 7)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df = pd.read_csv('coha.csv')\n",
    "df = df.query('year == 1950')\n",
    "# df.to_csv('1950.csv')\n",
    "df.columns\n",
    "print(df.shape)\n",
    "# Find stories about work\n",
    "df['target'] = (df.text.str.contains('immigrant|emmigrant', flags=re.IGNORECASE)).astype(int)\n",
    "tgts = df[df.target == 1]\n",
    "tgts.iloc[1,:].text\n",
    "print(tgts.shape)\n",
    "text = ''\n",
    "for index, row in tgts.iterrows():\n",
    "    text += row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7b7fb57a3142bfad2eef64233fb2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp_qa = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9553149419422766,\n",
       " 'start': 558,\n",
       " 'end': 590,\n",
       " 'answer': 'Mexican and West Indian laborers'}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=text[:50000], question='Who are immigrants?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.4751566728111527,\n",
       " 'start': 109,\n",
       " 'end': 123,\n",
       " 'answer': 'New York Times'}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many emmigrants arrived at Ellis Island in NY during the late 19th century\n",
    "nlp_qa(context=text[:50000], question='Where are emmigrants?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2151304264844356,\n",
       " 'start': 36908,\n",
       " 'end': 36932,\n",
       " 'answer': 'visibly seeking its name'}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=text[:50000], question='Why do immigrants move?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6973988922722825,\n",
       " 'start': 15346,\n",
       " 'end': 15364,\n",
       " 'answer': 'Greenwood Cemetery'}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greenwood Cemetary is a cementary in Brooklyn, NY\n",
    "nlp_qa(context=text[:50000], question='Where do immigrants move?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3912705171484987,\n",
       " 'start': 29079,\n",
       " 'end': 29088,\n",
       " 'answer': 'streetcar'}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=text[:50000], question='How do immigrants move?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation using BERT\n",
    "\n",
    "The last method which we will explore is text generation. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, such as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n",
    "\n",
    "These models can be quite impressive, even uncanny in how human like they sound. Check out this [cool website](https://transformer.huggingface.co), which allows you to write with a transformer. The website is built by the folks who wrote the package we are using. The code underneath the website can be found in their examples: [run_generation.py](https://github.com/huggingface/transformers/blob/master/examples/run_generation.py).\n",
    "\n",
    "We will be using the built in generate function, but the example file has more detailed code which allows you to set the seed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9802255597933218, 'start': 14594, 'end': 14600, 'answer': 'Africa'}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2803537c47f4e0580fc82fe59556bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0fd65a9b18457fb09ae521043d4ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6843047f4d1e4d98a53e80d90ad3d40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5aab04cb9479c9c2feed35d2dbbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing that we like to do more than analyse data all day long and then try to figure out what's going on.\n",
      "\n",
      "\"We're not going to be able to do that. We're not going to be able to do that.!\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Nothing that we like to do more than analyse data all day long and\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. A little creepy, and as we can see, far from perfect: GPT doesn't alwats work out flawlessly, but it sometimes can, and we will try and see if fine-tuning helps. We are going to tune the model on a complete dataset of Trump tweets, as they have a set of distinctive, highly identifiable qualities.\n",
    "\n",
    "### Creating a domain-specific language model\n",
    "\n",
    "One of the most exciting things about BERT and GPT is being able to retune them the way we want to. We will be training models to perform two tasks - one is to create a BERT with an \"accent\", by traning a model with english news data from the UK, from the US, and from India. We will also train a language generation model with a bunch of Trump tweets. \n",
    "\n",
    "We can train models specifically over a certain domain to make its language generation similar to that domain. \n",
    "[run_language modelling.py](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py), followed by [run_generation.py](https://github.com/huggingface/transformers/blob/master/examples/run_generation.py). I've downloaded these files and added them to this directory so we can run them through the notebook. You are encouraged to look at these files to get a rough idea of what is going on.\n",
    "\n",
    "### Loading Data \n",
    "\n",
    "We want to now get our Trump tweets and our English news datasets ready. The data the scripts expect is just a text file with relevant data. We load the Trump tweets and then write them to disk as train and test files with only data. I leave the original dataframes in case you would like to use it for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"../../data/trump_tweets\"):\n",
    "    dfs.append(pd.read_json(\"../../data/trump_tweets/\" + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(dfs)\n",
    "df = pd.read_csv('churchill.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mass Effects in Modern Life</td>\n",
       "      <td>Is the march of events ordered and guided by e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lights are Going Out</td>\n",
       "      <td>I avail myself with relief of the opportunity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Hush Over Europe</td>\n",
       "      <td>There is a hush over all Europe, nay, over all...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>War speech</td>\n",
       "      <td>In this solemn hour it is a consolation to rec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Years Hence</td>\n",
       "      <td>The great mass of human beings, absorbed in th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        speech  \\\n",
       "0  Mass Effects in Modern Life   \n",
       "1     The Lights are Going Out   \n",
       "2           A Hush Over Europe   \n",
       "3                   War speech   \n",
       "4            Fifty Years Hence   \n",
       "\n",
       "                                                text  Unnamed: 2  Unnamed: 3  \\\n",
       "0  Is the march of events ordered and guided by e...         NaN         NaN   \n",
       "1  I avail myself with relief of the opportunity ...         NaN         NaN   \n",
       "2  There is a hush over all Europe, nay, over all...         NaN         NaN   \n",
       "3  In this solemn hour it is a consolation to rec...         NaN         NaN   \n",
       "4  The great mass of human beings, absorbed in th...         NaN         NaN   \n",
       "\n",
       "   Unnamed: 4  Unnamed: 5  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(df['text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    The great mass of human beings, absorbed in th...\n",
       "1    I avail myself with relief of the opportunity ...\n",
       "0    Is the march of events ordered and guided by e...\n",
       "5    The Prime Minister, in what I think it is not ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text.to_frame().to_csv(r'train_text_churchill', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_frame().to_csv(r'test_text_churchill', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now used the Google Colab GPUs to train the Trump tweet models. We'll be doing the same for our blog posts too.\n",
    "\n",
    "### GloWBe dataset\n",
    "\n",
    "We'll now load up the GloWbe (Corpus of Global Web-Based English) dataset which have different texts from different countries. We'll try and draw out texts from only the US, UK and India. We'll then save these to disk. Note that this is a Davies Corpora dataset: the full download can be done with the Dropbox link I sent in an announcement a few weeks ago. The whole download is about 3.5 GB but we only need two files, which are anout 250 MB each. The other files might be useful for your research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucem_illud_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"/Users/bhargavvader/Downloads/Academics_tech/corpora/GloWbE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the exact name of the files\n",
    "us = \"/text_us_blog_jfy.zip\"\n",
    "gb = \"/text_gb_blog_akq.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_us_blog_jfy.zip\n"
     ]
    }
   ],
   "source": [
    "us_texts = lucem_illud_2020.loadDavies(address, corpus_style=\"us_blog\", num_files=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_gb_blog_akq.zip\n"
     ]
    }
   ],
   "source": [
    "gb_texts = lucem_illud_2020.loadDavies(address, corpus_style=\"gb_blog\", num_files=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dictionary with document ids mapping to text. Since we don't need any information but the text, we can just save these to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'< p > Many workers within the UK are required to wear an uniform for work but very few are aware they could really claim back some money from the tax man to help with the price of washing or repairing the uniform HMRC will actually pay money back once again to those individuals who are eligible even dating back four years worth of washing < p > In order to find out about claiming a tax rebate on uniform it is worth having a look online to find out whether or not you will be eligible The conditions are fairly straightforward you just have to wear a recognisable work uniform which might contain a T shirt which displays a logo design or possibly some specialist protective clothing The type of the occupation is unrelated anyone from nurses to cops to electricians are able to claim As long as the uniform is worn at work is washed on your own and you are an UK tax payer then your chances are you will be eligible to claim are eligible how do you actually go about claiming your tax refund for washing uniform You can access the HMRC web site directly and complete the important forms to help you to claim your hard earned money back Or you can use an agent that is registered with the HMRC who are able to deal with the whole tax rebate on your behalf This may save you a great deal of time and effort and they may also have the ability to advise you on any other areas where you could claim a rebate for instance if you are required to supply your own tools within your job < p > The amount of money you can claim as a tax rebate on uniform will depend on your profession and how long you have already been wearing a work uniform for You might be in a position to claim a rebate for the past four years which could add up to a fine sum of money < p > In those times of economic decline most people are seeking to save lots of washing uniform can be an effective way to start saving a couple of pounds every month which over the course of a'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(us_texts.values())[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_texts(texts, file_name):\n",
    "    text = []\n",
    "    for doc in list(texts.values()):\n",
    "        text.append(' '.join(doc).replace(\"< h >\", \"\").replace(\"< p >\", \"\"))\n",
    "    train_text, test_text = train_test_split(text, test_size=0.2)\n",
    "    with open(file_name + \"_train\", 'w') as f:\n",
    "        for item in train_text:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    with open(file_name + \"_test\", 'w') as f:\n",
    "        for item in test_text:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_texts(us_texts, \"us_blog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_texts(gb_texts, \"gb_blog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the training and testing files for both US and GB blogs in English. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING - SHIFT TO GOOGLE COLAB OR GPU ENABLED MACHINE\n",
    "\n",
    "The [Google Colab file](https://colab.research.google.com/drive/1_G6iGqiXb-zPBTurRxd7cgGrXyNaKGsA) walks you through the process of fine-tuning models, as we did before for the classification task. Move now to the colab file to fine tune your models. Once you downloaded all the models and their information, place those files in the directory of the HW to use them as demonstrated below. \n",
    "\n",
    "\n",
    "\n",
    "### Running Scripts\n",
    "\n",
    "We use the scripts to do language modelling and text generation. The following cells run the code as if you would have run it in a terminal. I trained all of these models using the Googlr Colab file, and then saved the models to disk.\n",
    "\n",
    "#### Trump GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:28:56 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "05/27/2020 22:28:56 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /Users/tjh/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/27/2020 22:28:56 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/27/2020 22:28:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /Users/tjh/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/27/2020 22:28:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /Users/tjh/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/27/2020 22:28:58 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /Users/tjh/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/27/2020 22:29:01 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/27/2020 22:29:01 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cpu'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text_trump', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=0, no_cuda=False, num_train_epochs=1.0, output_dir='output_gpt_trump', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text_trump', warmup_steps=0, weight_decay=0.0)\n",
      "05/27/2020 22:29:01 - INFO - __main__ -   Creating features from dataset file at \n",
      "05/27/2020 22:29:06 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_train_text_trump\n",
      "05/27/2020 22:29:06 - INFO - __main__ -   ***** Running training *****\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Num examples = 669\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Num Epochs = 1\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/27/2020 22:29:06 - INFO - __main__ -     Total optimization steps = 168\n",
      "Epoch:   0%|                                              | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                        | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1%|â–                            | 1/168 [01:45<4:54:17, 105.74s/it]\u001b[A^C\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modelling.py --output_dir=output_gpt_trump --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_text_trump --do_eval --eval_data_file=test_text_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python: can't open file 'run_language_modeling.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modeling.py --output_dir=output_roberta_US --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=$TRAIN_FILE --do_eval --eval_data_file=$TEST_FILE --mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python run_language_modeling.py --output_dir=output_roberta_UK --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=$TRAIN_FILE --do_eval --eval_data_file=$TEST_FILE --mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COME BACK TO THIS NOTEBOOK to load and work with your trained model\n",
    "\n",
    "### Loading and using models\n",
    "\n",
    "Let us now load the four models we have and see how we can use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now - let us see what our Trump Tweet Bot looks like!\n",
    "You can generate text via command line using the command below. You can also load a model once it is saved - I trained my model using Google Colab, downloaded the model, and am loading it again via the command below. Note that you have to download all the files in your folder of the fine-tuned model to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   Model name 'output_trump_gpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_trump_gpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   Didn't find file output_trump_gpt/added_tokens.json. We won't load it.\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   loading file output_trump_gpt/vocab.json\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   loading file output_trump_gpt/merges.txt\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   loading file output_trump_gpt/special_tokens_map.json\n",
      "05/27/2020 22:47:03 - INFO - transformers.tokenization_utils -   loading file output_trump_gpt/tokenizer_config.json\n",
      "05/27/2020 22:47:03 - INFO - transformers.configuration_utils -   loading configuration file output_trump_gpt/config.json\n",
      "05/27/2020 22:47:03 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"run_generation.py\", line 263, in <module>\n",
      "    main()\n",
      "  File \"run_generation.py\", line 204, in main\n",
      "    model = model_class.from_pretrained(args.model_name_or_path)\n",
      "  File \"/Users/tjh/.virtualenvs/cca/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 602, in from_pretrained\n",
      "    pretrained_model_name_or_path,\n",
      "OSError: Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index'] found in directory output_trump_gpt or `from_tf` set to False\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --model_type=gpt2 --model_name_or_path=output_trump_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_trump = AutoTokenizer.from_pretrained(\"output_trump_gpt\")\n",
    "model_trump = AutoModelWithLMHead.from_pretrained(\"output_trump_gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama is going to be a disaster for the United States. He is a total loser. He is a total loser!\"\n",
      "\"\"\"@jeff_mcclaren: @realDonaldTrump @realDonaldTrump @foxandfriends @megynkelly @\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Obama is going to\"\n",
    "\n",
    "input = tokenizer_trump.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_trump.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_trump.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - our Trump bot is nasty, so we know our model trained well. What happens if we try the same sentence for our non-fine tuned model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama is going to be a very good president,\" said Sen. John McCain (R-Ariz.). \"He's going to be a very good president. He's going to be a very good president. He's going to be a very\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Obama is going to\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite the contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that generate a BERT-powered chatbot tuned on text related to your final project. What is interesting about this model, and how to does it compare to an untrained model? What does it reveal about the social game involved with your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention grader:\n",
    "\n",
    "The collab notebook is taking an extraordinarily long time to download the pytorch_model.bin file. I'm going to let this finish overnight and commit my results early Thurday. -Tim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check out our UK and GB embeddings - how do you think the two models will differ? Maybe in the way different words relate to each other in the same sentence? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_us_model_embedding = RobertaModel.from_pretrained('roberta_us')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_us_tokenizer = RobertaTokenizer.from_pretrained('roberta_us')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to visualise how words in a sentence or different or similar to each other. We will try to construct sentences where words might mean different things in different countries - in the US, people might eat chips with salsa, but in the UK, chips are what Americans call french fries, and might eat it fried fish instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Do you have your chips with fish or with salsa?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"He went out in just his undershirt and pants.\" #pants are underwear in Britain; maybe closer to an undershirt\n",
    "text2 = \"His braces completed the outfit.\" #braces are suspenders (in Britain); maybe closer to an outfit\n",
    "text3 = \"Does your pencil have a rubber on it?\" #rubber is an eraser in Britain); maybe closer to a pencil\n",
    "text4 = \"Was the bog closer to the forest or the house?\" #bog is a toilen in Britain); maybe closer to a house\n",
    "text5 = \"Are you taking the trolley or the train to the grocery market\" #trolley is a food carriage; possibly closer to a market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_diffs(text, roberta_us_model_embedding, roberta_us_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_gb_model_embedding = RobertaModel.from_pretrained('roberta_gb')\n",
    "roberta_gb_tokenizer = RobertaTokenizer.from_pretrained('roberta_gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_diffs(text, roberta_gb_model_embedding, roberta_gb_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see regarding the relations with chips and sala/fish? What about the other sentences? How about comparing sentence embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that tune BERT to at least two different textual samples. These could be from different corpora, distinct time periods, separate authors, alternative publishing outlets, etc. Then compare the meaning of words, phrases and sentences to each other across the separate models. What do they reveal about the social worlds inscribed by the distinctive samples?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cca",
   "language": "python",
   "name": "cca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
